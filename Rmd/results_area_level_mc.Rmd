# Robust Area Level Predictions

In this Section the statistical properties of the proposed predictors are 
further investigated. Using model based simulation studies the empirical bias 
and mean squared prediction error are compared over a veriety of simulation 
scenarios and between the spatial and temporal extensions to the FH model. The
proposed methods to estimate the MSPE of the predictions are presented
seperately in Section (?).

The simulation scenarios are developed under an area level model; meaning that
we consider the situation where we know the true sampling variances and generate
the Monte Carle repetitions directly from the area level model. This is a 
conceptual contrast to the setting in section (?) in which we consider the 
situation in which we estimate the sampling variances as part of the study and 
thus need to generate the data on the unit level. However the area level 
perspective is what is typically considered in the literature to evaluate area 
level models -- see for example @Fab10 and @Mar13 -- and hence is considered 
first.

Although the area level perspective on the data generating process may be 
incomplete, i.e. we assume the sampling variances to be known, it is in fact the
model under consideration. It presents the possibility to study the performance
of the estimation procedures when the model assumptions appear to be violated
due to outlying observations. However in this setting we are limited to the
study of area level outliers -- see also Section (?) -- since it is not obvious
how we can impose unit level outliers into an area level data generating
process.

Since several models with various correlation structures are considered it is
tempting to investigate a multitude of specifications. With this respect some
choices have been made to restrict the presentation of results to a concise set
supporting the understanding of different model specifications in the context of
outliers. Although we will see some benefits of utilizing spatial and temporal
correlation structures the study does not aim to show the superiority of such
methods but focus on the effect of outliers. With respect to outliers we only
consider non\hyp{}symmetric outliers since they represent a more realistic use
case. The choices of the simulation settings are presented in Section
\ref{sec:area_level_sim_setting} in detail; the results are then presented in
Section \ref{sec:area_level_sim_results}; followed by a discussion taking other
literature into account in Section \ref{sec:area_level_sim_results}.


## Simulation Scenarios
\label{sec:area_level_sim_setting}

In the following the concrete choices are presented regarding the setup of the
simulation study. To avoid the specification of too many scenarios only a
temporal setting is considered. Similar to the approach by @Mar13 the FH model 
and spatial FH model are treated as special cases when we only use the data from
the current time period. The temporal and spatio\hyp{}temporal extensions then 
use all available information, however predictions are only made for the current
time period. In this setting it is possible to compare the different model 
specifications under a unified strategy.

The area level model from which data is generated in each Monte Carlo repetition
is chosen to be:
$$y_{it} = 100 + 5  x_i + \re_{1i} + \re_{2it} + e_{it}$$
with $i = 1, \dots, D$ and $t = 1, \dots, T$ where $D = 40$ and $T = 10$. The
*current* time period is defined to be $t = T$.

- The single regressor, $x_i$, is a deterministic sequence defined as $x_i = 
\frac{i}{2D} + 1$ where $D = 40$ is the number of domains. This is a very
similar setting to the choice made by @Mar13, however it is constant over time.
- The sampling errors, $e_{it}$, are drawn from $e_{it} \sim \Distr{N}(0,
\sige)$. The sampling variances, $\sigma_{eit}^2 = \sige$, are known during the
estimation; they are defined as an ascending and equidistant sequence between 2
and 6: $\sige = \frac{4 (i - 1)}{D - 1} + 2$.
- The random effects components are generated generally from the spatio-temporal
model, i.e. $\re_{1i} \sim \text{SAR}(1)$ and $\re_{2it} \sim \text{AR}(1)$ --
see also the more concrete presentation in Section (?). Models with uncorrelated
random effects are deduced when the respective correlation parameter is set to 
zero. Since the impact of outliers is our main concern only scenarios are 
considered where $\rho = \rho_1 = \rho_2$ and $\sigma_u^2 = \sigma_1^2 = 
\sigma_2^2$. The concrete choices for $\rho$ and $\sigma_u^2$ depend on the 
respective scenario and are defined below.

The considered scenarios are now defined by the combination of spatial and
temporal correlation in combination with the presence of outliers:

- *(0, 0)* denotes the scenario in which we set $\rho = 0$ and $\sigma_u^2 = 2$,
i.e. we have uncorrelated random effects and no outliers.
- *(0.5, 0)* denotes the scenario in which we set $\rho = 0.5$ and $\sigma_u^2 =
2$. Here we have no outliers but both spatial and temporal correlation in the
random effects.
- *(0, u)* denotes the outlier scenario when we set $\rho = 0$. Area outliers
are the domains for which $i \in \{5, 15, 25, 35\}$ to avoid an artificial
setting in combination with $\sige$. For regular observations $\sigre = 2$.
Outliers are drawn from $\re_i \sim \Distr{N}(9, 25)$ and ignore any correlation
structure. Furthermore areas are also outlying observations over time. 
- *(0.5, u)* denotes the scenario in which outliers are generated in the same 
way as for *(0, u)* however $\rho = 0.5$ for the generation of the regular
observations.


## Quality Measures

The methods to be compared are the robust spatial and temporal extensions to the
FH model. The non\hyp{}robust methods are denoted by FH, SFH, TFH, and STFH; and
their robust counterparts by RFH, RSFH, RTFH, and RSTFH. In fact these methods
have been introduced as area level REBLUP, SREBLUP, TREBLUP, and STREBLUP in
Section (?) and are here abbreviated for notational simplicity. Furthermore we
have the bias corrected versions of the predictors using the correction of
Section (?). This correction is only applied to the robust predictions and the
respective models are referred to by RFH.BC, RSFH.BC, RTFH.BC, and RSTFH.BC.

To asses the quality of predictions under the various methods two measures are 
utilised: the relative bias (RBIAS) and relative root mean squared error 
(RRMSE). These measures are computed over all realisations of the Monte Carlo 
repetitions; overall $R = 500$ repetitions have been conducted. Let 
$\hat{\theta}^M_{ir}$ denote the the prediction for the $i$th area in the $r$th 
repetition with $r = 1, \dots, R$ under the model $M$ where $M$ is one of the
models under consideration, e.g. the RFH. The Monte Carlo RRMSE can then be
defined by:
$$
\text{RRMSE}_i^M = \sqrt{\frac{1}{R}\sum_{r = 1}^R \Paran{\frac{\hat{\theta}^M_{ir} - \theta_{ir}}{\theta_{ir}}}^2}
$$
where $\theta_{ir}$ denotes the true target statistic in the Monte Carlo
repitition $r$ and is defined by:
$$
\theta_{ir} = \theta_{iTr} = 100 + 5x_i + \re_{1ir} + \re_{2iTr}
$$
where the target statistic is defined as the true value in time period $t = T$.
The relative bias can be defined accordingly as:
$$
\text{RBIAS}_i^M = \frac{1}{R}\sum_{r = 1}^R \frac{\hat{\theta}^M_{ir} - \theta_{ir}}{\theta_{ir}}.
$$


## Results
\label{sec:area_level_sim_results}

![\textrrmse](figs/area_level_rrmse.pdf)

![\textrbias](figs/area_level_rbias.pdf)


## Discussion
\label{sec:area_level_sim_results}}
