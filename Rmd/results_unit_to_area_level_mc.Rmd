# From Unit to Area Level Contamination
\label{sec:results_unit}

In this Section a different approach is taken in that a model based simulation
study is conducted beginning with a unit level population. This is typical for
unit level models; see for example @Cha14 and @Sin09. However results for robust
area level models are often produced using area level data -- see for example
@Fab10 -- or studies using survey data -- see for example @Bel06 and @Xie07.
This area level perspective implicitly rules out any impact of unit level
outliers on area level models; and whether such observations can influence
predictions is the subject matter of this Section.

This changed perspective enables a more thorough investigation of the impact of 
unit level contamination in conjunction with area level models. Furthermore it 
is necessary to illuminate how we estimate the sampling variance of the direct 
estimator as this can also have an impact on domain predictions; so far these 
quantities have been assumed to be known. In the literature the estimation of 
the sampling variances is often connected to the application of smoothing 
techniques to stabilise these parameters -- see Section
\ref{sec:theory_sae_fh_mspe} for a review. Hence in this context several points
require scrutiny:

- Under the FH model we specify an area level model with a heteroscedastic 
sampling distribution. The model does not explain the source for this 
heteroscedasticity. In what follows two different sources are induced: one is 
the sample size varying across domains, and the other unit level outliers.
- When we begin from the unit level we may ask what the true sampling variance 
is; under the model this quantity is assumed to be known. In practice these 
values are estimated and are themselves unreliable if the target is the 
population variance. So it will be relevant to discuss how the FH estimator and 
the robust extension perform when the direct variance estimator instils an
additional source of uncertainty. Also it is unclear how smoothing techniques
interact with unit level outliers.
- In the context of unit level outliers it may be intuitive to suggest a robust 
direct estimator instead of the sample mean. Hence different robust direct
estimators are used as an alternative to the domain specific sample mean.

This discussion has practical implications but is conceptually not related to 
the question if we exploit the spatial and temporal correlation structures
present in the data. For this reason the following study focuses on the FH model
and excludes the spatial and temporal extensions. In principle these results
should apply to these extensions also; however this remains an avenue for
further research.

The present study is structured as follows: the following Section 
\ref{sec:results_unit_level_model} completes the formal link between the unit 
and area level. Essentially we need to specify what assumptions have been made
with respect to the unit level population model in order to establish a coherent
link between the population level, the sampled level, and the area level. Based
on these results Section \ref{sec:results_unit_sim_setting} presents the
simulation settings, Section \ref{sec:results_unit_measures} the investigated
estimation strategies; then in Section \ref{sec:results_unit_results} the
results of the Monte Carlo Simulation are presented.


## A Unit Level Population Model
\label{sec:results_unit_level_model}

In the following the unit level population model assumed for this study is 
presented. In contrast to the BHF model reviewed in Section \ref{sec:unit_level}
here we do not need the distinction between sampled and non\hyp{}sampled units.
Hence we begin with a liner mixed model for the population of the form:
$$
y_{ij} = x_i^\top \beta + \re_i + e_{ij}
$$
with $i = 1, \dots, D$ and $j = 1, \dots, N_i$. Here $x_i$ is a vector of 
auxiliary information and $\beta$ the vector of regression coefficients; $\re_i$
is a i.i.d. random variable: $\re_i \sim \Distr{N}(0, \sigre)$; and 
$e_{ij}$ is also a i.i.d. random variable: $e_{ij} \sim \Distr{N}(0, 
\sigma_e^2)$. Given this simple unit level model consider the case in which we
draw samples with simple random sampling without replacement (SRSWOR) in each
domain. Only the case is considered where units are observed for all domains.
The domain specific sample sizes are denoted by $n_i$. When we use the sample
mean as a direct estimator we can derive the area level model as:
$$
\bar{y}_i = \underbrace{x_i^\top \beta + \re_i}_{\theta_i} + \bar{e}_i
$$
with $i = 1, \dots, D$. Here $\bar{y}_i$ denotes the direct estimator and 
$\theta_i$ the true target statistic. The sampling errors, $\bar{e}_i$, are 
i.i.d. with $\bar{e}_i \sim \Distr{N}(0, \sige)$ where $\sige = 
\frac{\sigma_e^2}{n_i}$. In this simple setting $x_i$ and $\re_i$ are the same 
for the unit and area level since they are constant within domains. Also we see 
in the definition of $\sige$ that the only source for the heteroscedasticity are
the sample sizes, $n_i$. An additional source for heteroscedastic sample errors
may also be induced by unit level outliers.

## Simulation Scenarios
\label{sec:results_unit_sim_setting}

The model underlying the Monte Carlo study is given by:
$$y_{ij} = 100 + 5 x_i + \re_i + e_{ij}$$

- The regressor, $x_i$, is a deterministic sequence defined as in the 
model\hyp{}based scenarios before: $x_i = \frac{i}{2D} + 1$.
- From this model a population is generated in each Monte Carlo repetition. Each
domain is of size $N_i = 1000$ and we consider $D = 40$ as before.
- Samples are drawn with SRSWOR in each domain. The sample sizes are defined as 
$n_i \in \{5, \dots, 15\}$. They are sorted as ascending sequence in $i$. The 
sample sizes are chosen in correspondence to the variance of the unit error in
the non\hyp{}outlier scenario such that the sampling variances of the sample
means are an ascending sequence between 2 and 6.

With these settings several different choices for outlier contamination are
investigated. Here we can now consider unit and area level outliers:

- *(0, 0)* -- no contamination. Here $\re_i \sim \Distr{N}(0, 2)$ and
$e_{ij} \sim \Distr{N}(0, 32)$.
- *(u, 0)* -- area level outliers. Similar to the generation before the 
non\hyp{}contaminated domains are generated from $\re_i \sim \Distr{N}(0, 2)$
and $e_{ij} \sim \Distr{N}(0, 32)$. Outlying domains are domains with $i \in
\{5, 15, 25, 35\}$ and their respective random effect is given by $\re_i \sim
\Distr{N}(9, 25)$.
- *(0, e)* -- unit level outliers. The random effect is drawn from $\re_i \sim 
\Distr{N}(0, 2)$. Individual outliers are generated from a mixture of two 
independent normals: $e_{ij} \sim \delta_i \Distr{N}(0, 32) + (1 - \delta_i) 
\Distr{N}(20, 200)$ where $\delta$ is a Bernoulli random variable with 
$\Exp{P}(\delta = 1) = 0.8$ for domains with $i \in \{4, 14, 24, 34\}$ and set
to one otherwise. I.e. 10 per cent of the areas have 20 per cent of unit level 
observations which are generated from the outlier distribution. 
- *(0, e-sym)* -- symmetric unit level outliers. This scenario is the same as
*(0, e)* with the unit level outlier distribution replaced by $\Distr{N}(0,
200)$. Hence here symmetric unit level outliers are imposed.
- *(u, e)* -- unit and area level outliers. The area level contamination is
imposed as in *(u, 0)* and the unit level contamination as in *(0, e)*.


## Quality Measures and Considered Methods
\label{sec:results_unit_measures}

Two measures are utilised to assess the quality of predictions: the Monte Carlo 
RRMSPE and Monte Carlo RBIAS. These quantities are computed according to Section
\ref{sec:area_level_sim_qm}. The performance is studied for several methods; the
non\hyp{}robust predictions under the FH model and robust prediction referred to
as RFH. For the robust predictions the tuning constant is fixed at a value of
1.345. The following modelling strategies are considered:

- SM -- denotes the sample mean. Since we sample with SRSWOR an unbiased direct
estimator is the sample mean.
- RM -- denotes a robust direct estimator. Here the sample median is used.
- FH.SM -- is the non\hyp{}robust prediction under the FH model. This model is
based on the sample mean and uses the direct variance estimate as sampling
variance for each domain: $\sige \coloneqq \frac{s_i^2}{n_i}$.
- RFH.SM -- is the robust prediction based the sample mean. The same setup as
for FH.SM is used.
- FH.SM.GVF -- is the non\hyp{}robust prediction under the FH model using a 
generalised variance function. In contrast to FH.SM a generalised variance 
function is used as an estimator for the sampling variance: $\sige \coloneqq 
\frac{\tilde{s}^2}{n_i}$ with
$$
\tilde{s}^2 = \frac{1}{n - D} \sum_{i = 1}^D (n_i - 1) s_i^2
$$
where $s^2_i$ denotes the sample variance for domain $i$ and $n = \sum_{i = 1}^D
n_i$.
- RFH.SM.GVF -- is the robust prediction using the generalised variance function.
This has the same setup as the FH.SM.GVF using the robust prediction.
- RFH.SM.BC -- is the robust prediction with the sample mean as direct estimator
and direct variance estimates. The predictions are bias corrected as described
in Section \ref{sec:rfhbiascorrection}.
- FH.RM -- is the non\hyp{}robust prediction based on the sample median. As 
sampling variance a robust estimator is used based on the median absolute
deviation (MAD): $\sige \coloneqq \frac{\text{MAD}_i^2}{n_i}$.
- RFH.RM -- is the robust prediction based on the sample median. The sampling
variances are estimated as for the FH.RM method.


## Results
\label{sec:results_unit_results}

To summarise the results of this study consider Figure \ref{fig:unit_mse} and
\ref{fig:unit_bias}. With these results the following observations can be made:

1. There is only a small advantage in using generalised variance functions as an
alternative to direct variance estimates.
2. The robust FH prediction has no additional effect under unit level outliers.
3. A robust direct estimator has no advantage over the sample mean.

\begin{figure}[htbp]
\centering
\includegraphics[width = \textwidth]{figs/unit_mse.pdf}
\caption[Relative Root Mean Squared Prediction Error for Domain Predictions]{\label{fig:unit_mse}Relative Root Mean Squared Prediction Error for Domain Predictions}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width = \textwidth]{figs/unit_bias.pdf}
\caption[Relative Bias for Domain Predictions]{\label{fig:unit_bias}Relative Bias for Domain Predictions}
\end{figure}

The first observation to make is that the particular choice for the generalised
variance function (GVF) does not show a significant gain in performance.
@Wol07[272-273] points out that the main benefits in using GVFs may be to reduce
the computational effort, to ease the communication of results, and achieve some
gain in stability. He argues that we can expect a gain in stability since 
instead of many parameters -- one for each domain -- fewer and hence more stable
parameters can be estimated. However he also notes that there is no theoretical
underpinning for this claim. The discussion in Section
\ref{sec:theory_sae_fh_mspe} showed that despite this lack of theory the use of
generalised variance functions is often preferred in practical applications. 
Hence it may well be that we tend to observe results which are specific to this
simulation setting.

Some differences when using GVFs can be observed with respect to the RBIAS. In a
scenario with non\hyp{}symmetric unit level outliers we can observe an increase
of the RBIAS. What happens here is that the overall variance is smoothed. Hence 
smaller sampling variances, $\sige$, are assigned to the the outlying domains 
making them appear to be more reliable measurements. This results in a stronger
impact of the outlying domains on the predictions and thus an increase in bias.
In Section \ref{sec:overly-influencial-observations} this effect is referred to
as the *creation of overly influential observations*.

In the simulation scenario here considered the unit level outlier contamination
does not influence the estimation of the GVF. In a different setting with a
stronger contamination the GVF can be expected to overestimate the true sampling
variances. In preliminary experiments this leads to a loss in efficiency in terms
of RRMSPE.

The second observation is that the robust prediction under an FH model does not 
improve the predictions under unit level contamination. The results under 
symmetric unit level contamination show that the FH model has a self adjusting 
effect as was described in Section \ref{sec:unit-level-outliers}. The prediction
mechanism under the FH model gives more weight to the linear predictor for the
outlying domains since we observe a larger sampling variance for these type of
outliers. This is not an undesirable property so long as the linear prediction
is a good fit for these observations. When we compare these results with the
non\hyp{}symmetric outlier scenario -- *(0, e)* -- we can see that the effect of
unit level contamination on the prediction is small overall. This is so for all
modelling strategies except when using GVFs for the reasons outlined above.
However in these situations we introduce a bias for the outlying domains. In
contrast to the bias correction for unit level models -- see Section 
\ref{sec:robustbc} for a review -- such a bias cannot be corrected using area 
level data.

The use of the RFH model is limited when we consider unit level contamination. 
The self adjusting effect of the FH model is in general also present in the 
robust prediction. When we consider the use of the GVF it can happen,
particularly with more extreme outlier contamination, that the RFH model becomes
preferable. This is so because we create overly influential observations which,
from their design, do not differ from area level outlier -- at least from the
area level perspective.

The third observation is that a robust direct estimator, here the median, has no
additional advantage over the sample mean. Here several points need to be 
mentioned. First, using a robust estimator may be problematic when we consider 
small samples in that the median will itself have an even higher variance than 
the sample mean. The additional gain with respect to the unit level
contamination does not seem to outweigh this shortcoming -- at least in the
scenarios considered. This is also true when we consider this same symmetric
unit level outlier setting in all instead of only in a small number of domains.
Second, the variance estimation of a robust direct method is usually also
problematic, again, because we are considering small samples. In practice it may
be desirable to use a bootstrap for estimating the variance of the sample
median. With these small samples the results have been disappointing and have
not lead to an improvement in the area level predictions. Hence the MAD seems to
provide a sensible alternative. Third, it may be argued that a different robust
method should be considered. An M-type estimator for the sample mean, in
conjunction with a robust variance estimator, has also been considered. Compared
to the median very similar results have been obtained in this case; consequently
these results have been omitted here.


## Discussion

There are two main reasons to consider a robust area level model. First this
helps to make the prediction robust against area level outliers. Second it
facilitates to protect against the overly influential observations which may
occur upon using GVFs to smooth the sampling variances. However a more thorough
investigation of the use of GVFs may be necessary to come to a plausible
recommendation since the simulation setup has not shown a significant
improvement in the overall predictions.

With respect to unit level outliers we can see a self adjusting effect in the 
robust and non\hyp{}robust prediction under the FH model. This adjustment 
replaces the predictions for outliers with the linear predictor which
constitutes an improvement in those cases in which this predictor is suitable,
e.g. design unbiased. In principle we face the same problem as for robust
methods using unit level data in that again we introduce a bias. However at
present it is unclear how a bias correction can be developed for these
situations when only area level data is observed. The proposed bias correction
can have a beneficial effect when we consider area level contamination; however
it does not provide any advantage with respect to unit level outliers.

The use of robust direct estimators has not proved to be encouraging. It may be
that to try to solve an efficiency problem of the sample mean by replacing it
with an even less efficient estimator is the main reason here. This effect can
well be due to the small sample sizes considered in SAE, particularly in this 
simulation setup. These small sample sizes then lead to a less efficient 
estimate for the domain specific mean and also its variance. Using an area level
model has not shown itself to outweigh this effect.

