# Extensions to the Fay-Herriot Model

## Spatial Fay-Herriot Model

## Temporal Fay-Herriot Model

## Spatio-Temporal Fay-Herriot Model

The variance structure under model \eq{eq:tfh} can again
be derived as a special mixed linear model. Hence the concrete variance
components are stated with respect to model \eq{eq:lmm}. Here $V_e = 
\diag\Paran{\{\{\sigma_{eit}^2\}_{t=1}^T\}_{i = 1}^D}$ and is similar to the 
structure under model \eq{eq:fh}. $V_u(\delta) = \diag \left(\sigma_u^2 \mat{I}_D, 
\sigma_2^2 \Omega(\rho_2)\right)$ which depends on the vector of unknown variance 
parameters $\delta = (\sigma_1^2, \rho_2, \sigma_2^2)$. $\Omega_2(\rho_2)$ has a
block diagonal structure with $\Omega_{2i}(\rho_2)$ denoting the block for
observation $i$ with:
  $$
    \Omega_{2i}(\rho_2) = \frac{1}{1-\rho_2^2}
    \left(
      \begin{matrix}
      1 & \rho_2 & \cdots & \rho_2^{T-2}& \rho_2^{T-1}\\
      \rho_2 & 1 & & & \rho_2^{T-2} \\
      \vdots & & \ddots & & \vdots \\
      \rho_2^{T-2} &&& 1 & \rho_2 \\
      \rho_2^{T-1} & \rho_2^{T-2} & \cdots & \rho_2 & 1\\
      \end{matrix}
      \right)_{T\times T}
  $$
Furthermore $\mat{u}$$\mat{Z} = (\mat{I}_D, \mat{Z}_2)_{DT\times (D+DT)}$

$$
\tilde{y}_{it} = \theta_{it} + e_{it}
$$

 The
model error is composed of a spatial autoregressive process of order 1 (SAR(1))
and an autoregressive process of order 1 (AR(1)):
$$
\theta_{it} = \mat{x}^\top_{it}\beta + u_{1i} + u_{2it}
$$
where $u_{1i}$ and $u_{2it}$ follow a SAR(1) and AR(1) respectively:
$$
u_{1i} = \rho_1 \sum_{l\neq i}w_{il} u_{1l} + \epsilon_{1i}
$$
where $|\rho_1| < 1$ and $\epsilon_{1i} \sim \Distr{N}(0, \sigma_1^2)$ are
i.i.d. with $i = 1,\dots, D$. $w_{il}$ are the elements of $\mat{W}$ which is the
row standardized proximity matrix $\mat{W}^0$. The elements in $\mat{W}^0$ are equal to 1 if
areas are neighboured and 0 otherwise, thus the dimension of $\mat{W}^0$ is $D \times D$. As stated above $u_{2it}$ follows an
AR(1):
 Note that $u_{1i}$ and
$u_{2it}$ and $e_{it}$ are independent and the sampling error variance
parameters are assumed to be known. The model can then be stated as:
$$
\mat{y} = \mat{X}\beta + \mat{Z}\mat{u} + \mat{e},
$$
where $\mat{y}$ is the $DT\times 1$ vector containing $y_{it}$ as elements,
$\mat{X}$ is the $DT \times P$ design matrix containing the vectors
$\mat{x}^\top_{it}$ as rows, $\mat{u}$ is the $(D + DT) \times 1$ vector of model
errors and $\mat{e}$ the $DT \times 1$ vector of sampling errors $e_{it}$.
Note that $\mat{u} = (\mat{u}_1^\top, \mat{u}_2^\top)$ where the $D\times 1$ vector $\mat{u}_1$
and $DT \times 1$ vector $\mat{u}_2$ have $\mat{u}_{1i}$ and $\mat{u}_{2it}$ as elements
respectively. Furthermore $\mat{Z} = (\mat{Z}_1, \mat{Z}_2)$ has
dimension $DT \times (D+DT)$, where $\mat{Z}_1 = \mat{I}_D \otimes
\mat{1}_T$ ($\mat{I}_D$ denotes a $D\times D$ identity matrix and
$\mat{1}_T$ a $1 \times T$ vector of ones) has dimension $DT \times D$ and
$\mat{Z}_2$ is a $DT \times DT$ identity matrix.

Concerning the variance of $\mat{y}$ first consider the distributions of all
error components. $\mat{e} \sim \Distr{N}(\mat{0}, \mat{V}_e)$ where
$\mat{V}_e$ is a diagonal matrix with the known $\sigma^2_{eit}$ on the main
diagonal. $\mat{u} \sim \Distr{N}(\mat{0}, \mat{V}_u(\delta))$ with
the block diagonal covariance matrix $\mat{V}_u(\delta) =
\text{diag}(\sigma_1^2\Omega_1(\rho_1), \sigma_2^2\Omega_2(\rho_2))$ where
$\delta = (\sigma_1^2, \rho_1, \sigma_2^2, \rho_2)$.

$$
\Omega_1(\rho_1) = \left((\mat{I}_D - \rho_1\mat{W})^\top (\mat{I}_D - \rho_1\mat{W})\right)^{-1}
$$
and follows from the SAR(1) process in the model errors. 


The variance of $\mat{y}$ can thus be stated as:
$$
\mathbb{V}(\mat{y}) = \mat{V}(\delta) = \mat{Z}\mat{V}_u(\delta)\mat{Z}^\top + \mat{V}_e
$$
The BLUE of $\beta$ and BLUP of $\delta$ can be stated as \citep[see][]{Hen75}:
$$
\tilde{\beta}(\delta) = \left(\mat{X}^\top \mat{V}^{-1}(\delta) \mat{X} \right)^{-1} \mat{X}^\top \mat{V}^{-1}(\delta) \mat{y}
$$
$$
\tilde{\mat{u}}(\delta) = \mat{V}_u(\delta) \mat{Z}^\top \mat{V}^{-1}(\delta) \left(\mat{y} - \mat{X}\tilde{\beta}(\delta)\right)
$$
Hence the BLUP of $\mat{u}_1$ and $\mat{u}_2$ can be stated as:
$$
\tilde{\mat{u}}_1(\delta) = \sigma_1^2 \Omega_1(\rho_1) \mat{Z}^\top \mat{V}^{-1}(\delta) \left(\mat{y} - \mat{X}\tilde{\beta}(\delta)\right)
$$
$$
\tilde{\mat{u}}_2(\delta) = \sigma_2^2 \Omega_2(\rho_2) \mat{Z}^\top \mat{V}^{-1}(\delta) \left(\mat{y} - \mat{X}\tilde{\beta}(\delta)\right)
$$
Estimating $\delta$ leads to the EBLUE for $\beta$ and EBLUPs for $\mat{u}_1$ and
$\mat{u}_2$, hence an predictor for the area characteristic $\theta_{it}$ is given by:
$$
\hat{\theta}^{STFH}_{it} = \mat{x}_{it}^\top \hat{\beta} + \hat{\mat{u}}_{1i} + \hat{\mat{u}}_{2it}
$$
@Mar13 use a restricted maximum likelihood method to estimate $\delta$
  independently of $\beta$. An open question is if this approach can be applied
  for the robust spatio-temporal model. Thus we will continue with the
  discussion of robust small area methods.


# Robust Predictions under Area Level Models

## Robust Estimation Equations

## Pseudolinear Representation

\empty{
\begin{align*}
\sum_i \mat{X}_i^\top\mat{v}_i^{-1} v_{ii}^{\half} 
  \psi\Paran{v_{ii}^{-\half} (y_i - \mat{x}^\top_i\beta)} & = 0
\end{align*}
}


\empty{
\begin{align*}
\mat{X}^\top\mat{V}^{-1} \mat{U}^{\half} 
  \psi\Paran{\mat{U}^{-\half} (\mat{y} - \mat{X}\beta)} & = 0 \\
\underbrace{\mat{X}^\top\mat{V}^{-1} \mat{U}^{\half} \mat{W}_1
  \mat{U}^{-\half}}_{\mat{W}_1^*} (\mat{y} - \mat{X}\beta) & = 0 \\
\mat{W}_1^* \mat{y} & = \mat{W}_1^* \mat{X}\beta \\
\underbrace{\Paran{\mat{W}_1^* \mat{X}}^{-1} \mat{W}_1^*}_{\mat{A}} 
  \mat{y} & = \beta
\end{align*}
}

with

\empty{
\begin{align*}
\mat{A} = \Paran{\mat{X}^\top\mat{V}^{-1} \mat{U}^{\half} \mat{W}_1
  \mat{U}^{-\half} \mat{X}}^{-1} \mat{X}^\top\mat{V}^{-1} \mat{U}^{\half} \mat{W}_1
  \mat{U}^{-\half}
\end{align*}
}

\empty{
\begin{align*}
\mat{u} & = \mat{B}\Paran{\mat{I} - \mat{X}\mat{A}} \mat{y} \\
        & = \mat{B}\Paran{\mat{y} - \mat{X}\beta}
\end{align*}
}

\empty{
\begin{align*}
\mat{Z}^\top \mat{V}_e^{-\half} \psi \Paran{\mat{V}_e^{-\half} 
  \Paran{\mat{y}-\mat{X}\beta - \mat{Z} \mat{\re}}} 
  - \mat{V}_\re^{-\half} \psi\Paran{\mat{V}_\re^{-\half}\mat{\re}} & = 0 \\
%
\underbrace{\mat{Z}^\top \mat{V}_e^{-\half} \mat{W}_2 \mat{V}_e^{-\half}}_{\mat{W}^*_2}
  \Paran{\mat{y}-\mat{X}\beta - \mat{Z} \mat{\re}} 
  - \underbrace{\mat{V}_\re^{-\half} \mat{W}_3 \mat{V}_\re^{-\half}}_{\mat{W}_3^*} \mat{\re} & = 0
%  
\end{align*}
}

\empty{
\begin{align*}
\mat{W}_2^* \Paran{\mat{y}-\mat{X}\beta - \mat{Z} \mat{\re}} & = 
  \mat{W}_3^*\mat{\re} \\
%
\mat{W}_2^* \Paran{\mat{y}-\mat{X}\beta} & = 
  \Paran{\mat{W}_2^*\mat{Z} + \mat{W}_3^*} \mat{\re} \\
%
\underbrace{\Paran{\mat{W}_2^*\mat{Z} + \mat{W}_3^*}^{-1} \mat{W}_2^*}_{\mat{B}} 
  \Paran{\mat{y}-\mat{X}\beta} & = \mat{\re}
\end{align*}
}

where 
$$
\mat{B}(\mat{u}) = \mat{B} = 
  \Paran{
    \mat{Z}^\top \mat{V}_e^{-\half} \mat{W}_2 \mat{V}_e^{-\half} \mat{Z}
    + \mat{V}_\re^{-\half} \mat{W}_3 \mat{V}_\re^{-\half}
  }^{-1} \mat{Z}^\top \mat{V}_e^{-\half} \mat{W}_2 \mat{V}_e^{-\half}
$$


## Solutions to the Robust Estimation Equations

### Newton Raphson Algorithms

@Sin09 propose a Newton-Raphson algorithm to solve equations \ref{eq:rml_beta} and \ref{eq:rml_theta} iteratively. The iterative equation for $\beta$ is given by:
$$
\beta^{(m+1)} = \beta^{(m)} + \left(\mathbf{X}^\top \mathbf{V}^{-1}\mathbf{D}(\beta^{(m)})\mathbf{X}\right)^{-1}\mathbf{X}^\top\mathbf{V}^{-1}\mathbf{U}^{\frac{1}{2}}\psi(\mathbf{r}(\beta^{(m)}))
$$
where $\mathbf{D}(\beta) = \frac{\partial \psi(\mathbf{r})}{\partial \mathbf{r}}$ is a diagonal matrix of the same order as $\mathbf{V}$ with elements
$$
D_{jj} =
\begin{cases}
1 \text{ for } |r_j|\leq b\\
0 \text{ else}
\end{cases}
\text{ , } j = 1, \dots, n
$$
The iterative equation for $\theta$ can be stated as:
$$
\theta^{(m+1)} = \theta^{(m)} - \left( \Phi'(\theta^{(m)}) \right)^{-1} \Phi(\theta^{(m)})
$$
where $\Phi'(\theta^m)$ is the derivative of $\Phi(\theta)$ evaluated at $\theta^{(m)}$. The derivative of $\Phi$ is given by \cite[p.53]{Sch11}:
\begin{align}
\label{eq:deriv_Phi_theta}
\frac{\partial\Phi}{\partial\theta_l} = 2\frac{\partial}{\partial\theta_l}\left(\psi(\mathbf{r})^\top\mathbf{U}^{\frac{1}{2}}\mathbf{V}^{-1}\right)\frac{\partial\mathbf{V}}{\partial\theta_l}\mathbf{V}^{-1}\mathbf{U}^{\frac{1}{2}}\psi(\mathbf{r}) + \tr\left(\mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\theta_l}\mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\theta_l} K\right)
\end{align}
where
$$
\frac{\partial}{\partial\theta_l}\left(\psi(\mathbf{r})^\top\mathbf{U}^{\frac{1}{2}}\mathbf{V}^{-1}\right) = \frac{\partial}{\partial\theta_l}(\psi(\mathbf{r})^\top)\mathbf{U}^\frac{1}{2}\mathbf{V}^{-1} + \psi(\mathbf{r})^\top\frac{\partial}{\partial\theta_l}(\mathbf{U}^\frac{1}{2})\mathbf{V}^{-1} - \psi(\mathbf{r})^\top\mathbf{U}^\frac{1}{2}\mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\theta_l}\mathbf{V}^{-1}.
$$
In @Sch11 adopted this procedure for the Spatial Robust EBLUP and essentially we will follow the same procedure @Sch11[p.74ff.]. Thus we will directly consider the algorithm for the Spatio Temporal model introduced earlier. Since the model considered by @Sin09 contained a block diagonal variance structure where all off-diagonals are zero, equation \ref{eq:deriv_Phi_theta} is valid with respect to the earlier specified variance parameters $\sigma_1^2$ and $\sigma_2^2$ from the spatio temporal Fay Herriot model. The derivative of $\Phi$ with respect to $\rho_1$ and $\rho_2$, however, is different. To adapt the notation, let $\theta = (\sigma_1^2, \sigma_2^2)$ for which equation \ref{eq:deriv_Phi_theta} holds. Let $\rho = (\rho_1, \rho_2)$ denote the vector of correlation parameters as they already have been defined above. Then the iterative equation for $\rho$ is can be stated as:
$$
\rho^{(m+1)} = \rho^{(m)} + \left(\Phi'(\rho^{(m)}\right)^{-1}\Phi(\rho^{(m)})
$$
where the derivative of $\Phi$ with respect to $\rho$ is given by @Sch11[p.76]:

\begin{align*}
\frac{\partial\Phi}{\partial\rho_l} =& 2\frac{\partial}{\partial\rho_l}\left(\psi(\mathbf{r})^\top\mathbf{U}^{\frac{1}{2}}\mathbf{V}^{-1}\right)\frac{\partial\mathbf{V}}{\partial\rho_l}\mathbf{V}^{-1}\mathbf{U}^{\frac{1}{2}}\psi(\mathbf{r})\\
&+ \psi(\mathbf{r})^\top\mathbf{U}^{\frac{1}{2}}\mathbf{V}^{-1} \frac{\partial\mathbf{V}}{\partial\rho_l\partial\rho_l} \mathbf{V}^{-1}\mathbf{U}^{\frac{1}{2}}\psi(\mathbf{r}) \\
&+ \tr\left(\mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\rho_l\partial\rho_l} K - \mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\theta_l}\mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\theta_l} K\right)
\end{align*}

The partial derivatives of $\mathbf{V}$ with respect to $\theta$ and $\rho$ are given by:

\begin{align*}
\frac{\partial\mathbf{V}}{\partial\sigma_1^2} =& \mathbf{Z}_1\Omega_1(\rho_1)\mathbf{Z}_1^\top \\
\frac{\partial\mathbf{V}}{\partial\sigma_2^2} =& \Omega_2(\rho_2) \\
\frac{\partial\mathbf{V}}{\partial\rho_1} =& -\sigma_1^2\mathbf{Z}_1\Omega_1(\rho_1)\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1}\Omega_1(\rho_1)\mathbf{Z}^\top_1 \\
\frac{\partial\mathbf{V}}{\partial\rho_2} =& \sigma_2^2 \diag\left(\frac{\partial\Omega_{2d}(\rho_2)}{\partial\rho_2}\right) \\
\frac{\partial\mathbf{V}}{\partial\rho_1\partial\rho_1} =& -\sigma_1^2\mathbf{Z}_1\frac{\partial\Omega_1(\rho_1)}{\partial\rho_1}\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1}\Omega_1(\rho_1)\mathbf{Z}^\top_1 \\
&-\sigma_1^2\mathbf{Z}_1\Omega_1(\rho_1)\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1\partial\rho_1}\Omega_1(\rho_1)\mathbf{Z}^\top_1 \\
&-\sigma_1^2\mathbf{Z}_1\Omega_1(\rho_1)\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1}\frac{\partial\Omega_1(\rho_1)}{\partial\rho_1}\mathbf{Z}^\top_1 \\
\frac{\partial\mathbf{V}}{\partial\rho_2\partial\rho_2} =& \text{Needs to be TEXed}
\end{align*}

where

\begin{align*}
\frac{\Omega_1(\rho_1)}{\partial\rho_1} =& -\Omega_1(\rho_1)\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1}\Omega_1(\rho_1) \text{ , }\\
\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1} =& -\mathbf{W} - \mathbf{W}^\top + 2\rho_1\mathbf{W}^\top\mathbf{W} \text{ , } \\
\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1\partial\rho_1} =& 2\mathbf{W}^\top\mathbf{W}\\
\frac{\partial\Omega_{2d}(\rho_2)}{\partial\rho_2} =& \frac{1}{1-\rho_2^2}
\left(
\begin{matrix}
0 & 1 & \cdots & \cdots & (T-1)\rho_2^{T-2}\\
1 & 0 & & & (T-2)\rho_2^{T-3} \\
\vdots & & \ddots & & \vdots \\
(T-2)\rho_2^{T-3} &&& 0 & 1 \\
(T-1)\rho_2^{T-2} & \cdots & \cdots & 1 & 0\\
\end{matrix}
\right) + \frac{2\rho_2\Omega_{2d}(\rho_2)}{1-\rho_2^2}
\end{align*}

Having identified all iterative equations the adapted algorithm from @Sch11 is as follows:

- Choose initial values for $\beta^0$, $\theta^0$ and $\rho^0$.
  - Compute $\beta^{(m+1)}$, with given variance parameters and correlation parameters
	- Compute $\theta^{(m+1)}$, with given regression and correlation parameters
	- Compute $\rho^{(m+1)}$, with given variance and regression parameters

- Continue step 2 until the following stopping rule holds:

\begin{align*}
	||\beta^{(m+1)}- \beta^{(m)}||^2 <& \text{const} \\
	(\sigma_1^{2(m+1)} - \sigma_1^{2(m)})^2 + (\sigma_2^{2(m+1)} - \sigma_2^{2(m)})^2 + (\rho_1^{(m+1)} - \rho_1^{(m)})^2 + (\rho_2^{(m+1)} - \rho_2^{(m)})^2 <& \text{const}
\end{align*}


### Fixed Point Algorithms

Inspired by: Chatrchi Golshid (2012): Robust Estimation of Variance Components
in Small Area Estimation, Master-Thesis, Ottawa, Ontario, Canada: p. 16ff.:

\begin{quote}
The fixed-point iterative method relies on the fixed-point theorem: "If g(x) is
a continuous function for all $x \in [a; b]$, then $g$ has a fixed point in $[a;
b]$." This can be proven by assuming that $g(a)\geq a$ and $g(b)\leq b$. Since
$g$ is continuous the intermediate value theorem guarantees that there exists a
$c$ such that $g(c) = c$.
\end{quote}

Starting from equation \ref{eq:rml_theta} where $\theta = (\sigma_1^2,
\sigma_2^2)$ and $(\rho_1, \rho_2)$ are assumed to be known, we can rewrite the
equation such that:

\begin{multline}
\label{eq:rml_theta_fp}
\Phi_l(\theta) = \psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}
\frac{\partial\mat{V}}{\partial\theta_l}
\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) -\\
\Tr{K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l}
(\mat{Z}\mat{V}_\re\mat{Z}^\top)^{-1} (\mat{Z}\mat{V}_\re\mat{Z}^\top)} = 0
\end{multline}

Note that because the matrix $\mat{V}_e$ is assumed to be known for the FH
model, it can be omitted. Let $\mat{0}_{r\times c}$ define a matrix filled with
$0$ of dimension $(r \times c)$ then:

\begin{align*}
\mat{Z}\mat{V}_u\mat{Z}^\top =& \mat{Z}\left(\begin{matrix}
\sigma_1^2\Omega_1 & \mat{0}_{D\times DT}\\
\mat{0}_{DT\times D} &  \sigma_2^2\Omega_2
\end{matrix}\right)\mat{Z}^\top \\
=& \mat{Z}
\left[
\sigma_1^2\left(\begin{matrix}
\Omega_1 & \mat{0}_{D\times DT} \\
\mat{0}_{DT\times D} &  \mat{0}_{DT\times DT}
\end{matrix}\right) +
\sigma_2^2\left(\begin{matrix}
\mat{0}_{D\times D} & \mat{0}_{D\times DT} \\
\mat{0}_{DT\times D} & \Omega_2
\end{matrix}\right)
\right]\mat{Z}^\top \\
=& \left(\begin{matrix}\mat{Z}\bar{\Omega}_1\mat{Z}^\top & \mat{Z}\bar{\Omega}_2\mat{Z}^\top\end{matrix}\right)
\left(\begin{matrix}
\sigma_1^2 \\
\sigma_2^2
\end{matrix}\right)
\end{align*}

Thus equation \ref{eq:rml_theta_fp} can be rewritten to:

\begin{multline*}
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) = \\ \tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \left(\begin{matrix}\mat{Z}\bar{\Omega}_1\mat{Z}^\top & \mat{Z}\bar{\Omega}_2\mat{Z}^\top\end{matrix}\right)\left(\begin{matrix}
\sigma_1^2 \\
\sigma_2^2
\end{matrix}\right)\right)
\end{multline*}

Let
$$
\left(\begin{matrix}
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_1^2}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) \\
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_2^2}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r})
\end{matrix}\right)
= a(\theta) \text{ ,}
$$
then
$$
\theta = \left(\begin{matrix}
\sigma_1^2 \\
\sigma_2^2
\end{matrix}\right) = A(\theta)^{-1} a(\theta) \text{ ,}
$$
where
\begin{align*}
A(\theta) = \left(\begin{matrix}
\tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_1^2} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \mat{Z}\bar{\Omega}_1\mat{Z}^\top \right) &
\tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_1^2} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \mat{Z}\bar{\Omega}_2\mat{Z}^\top \right) \\
\tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_2^2} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \mat{Z}\bar{\Omega}_1\mat{Z}^\top \right) &
\tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_2^2} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \mat{Z}\bar{\Omega}_2\mat{Z}^\top \right)
\end{matrix}\right) \text{.}
\end{align*}
So, the fixed point algorithm can be presented as follows:
$$
\theta^{m+1} = A(\theta^{(m)})^{-1} a(\theta^{(m)})
$$

At this time the fixed-point algorithm for $\theta = (\sigma_1^2, \sigma_2^2)$
will replace the corresponding step in Issue 1.

### N-S: Fixed-Point-Algorithm - Spatial Correlation

To extend the above algorithm to not only being used for the estimation of
$\theta = (\sigma_1^2, \sigma_2^2)$ but also for the spatial correlation
parameter $\rho_1$ reconsider:

\begin{eqnarray}
\label{eq:zVuZ_rho1_1}
\mat{Z}\mat{V}_u\mat{Z}^\top &=& \mat{Z}\left(\begin{matrix}
\sigma_1^2\Omega_1 & \mat{0}_{D\times DT}\\
\mat{0}_{DT\times D} &  \sigma_2^2\Omega_2
\end{matrix}\right)\mat{Z}^\top
\end{eqnarray}

and the specification of $\Omega_1(\rho_1) = \left((I-\rho_1\mat{W})^\top(I-\rho_1\mat{W})\right)^{-1}$:

\begin{align}
\sigma_1^2\Omega_1(\rho_1) &= \sigma_1^2\Omega_1\Omega_1(I-\rho_1\mat{W})^\top(I-\rho_1\mat{W}) \notag\\
&= \sigma_1^2\left(\Omega_1\Omega_1 -\rho_1\Omega_1\Omega_1\mat{W}^\top -\rho_1\Omega_1\Omega_1\mat{W} + \rho_1^2\Omega_1\Omega_1\mat{W}^\top\mat{W}\right) \notag\\
&= \sigma_1^2\left(\Omega_1\Omega_1 -\rho_1\Omega_1\Omega_1\mat{W}^\top\right) +\rho_1 \left(-\sigma_1^2\Omega_1\Omega_1\mat{W} + \sigma_1^2\rho_1\Omega_1\Omega_1\mat{W}^\top\mat{W}\right) \label{eq:zVuZ_rho1_2}
\end{align}

Thus equation \ref{eq:zVuZ_rho1_1} can be rewritten as:

\begin{align*}
\mat{Z}\mat{V}_u\mat{Z}^\top
&=\mat{Z}
\Biggr[
\sigma_1^2\left(\begin{matrix}
\Omega_1\Omega_1 -\rho_1\Omega_1\Omega_1\mat{W}^\top & \mat{0}_{D\times DT}\\
\mat{0}_{DT\times D} &  \mat{0}_{DT\times DT}
\end{matrix}\right)\\
&+\rho_1\left(\begin{matrix}
-\sigma_1^2\Omega_1\Omega_1\mat{W} + \sigma_1^2\rho_1\Omega_1\Omega_1\mat{W}^\top\mat{W} & \mat{0}_{D\times DT}\\
\mat{0}_{DT\times D} &  \mat{0}_{DT\times DT}
\end{matrix}\right)\\
&+\sigma_2^2\left(\begin{matrix}
\mat{0}_{D\times D} & \mat{0}_{D\times DT}\\
\mat{0}_{DT\times D} & \Omega_2
\end{matrix}\right)
\Biggr]
\mat{Z}^\top \\
&=\left(\begin{matrix}\mat{Z}\bar{\Omega}_{1, \sigma_1^2}\mat{Z}^\top &
\mat{Z}\bar{\Omega}_{1, \rho_1}\mat{Z}^\top & \mat{Z}\bar{\Omega}_2\mat{Z}^\top\end{matrix}\right)
\left(\begin{matrix}
\sigma_1^2 \\
\rho_1 \\
\sigma_2^2
\end{matrix}\right)
\end{align*}

Thus equation \ref{eq:rml_theta_fp} can be rewritten (analogously as above) to:

\begin{eqnarray*}
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) = \tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \left(\begin{matrix}\mat{Z}\bar{\Omega}_{1, \sigma_1^2}\mat{Z}^\top &
\mat{Z}\bar{\Omega}_{1, \rho_1}\mat{Z}^\top & \mat{Z}\bar{\Omega}_2\mat{Z}^\top\end{matrix}\right)
\left(\begin{matrix}
\sigma_1^2 \\
\rho_1 \\
\sigma_2^2
\end{matrix}\right)\right)
\end{eqnarray*}

Let

$$
\left(\begin{matrix}
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_1^2}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) \\
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\rho_1}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) \\
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_2^2}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r})
\end{matrix}\right)
= a(\theta) \text{ ,}
$$

then

$$
\theta = \left(\begin{matrix}
\sigma_1^2 \\
\rho_1 \\
\sigma_2^2
\end{matrix}\right) = A(\theta)^{-1} a(\theta) \text{ ,}
$$
where
\begin{align*}
A(\theta) = \left(\begin{matrix}
\tr\left(\gamma(\sigma_1^2) \mat{Z}\bar{\Omega}_{1,\sigma_1^2} \mat{Z}^\top \right) & \tr\left(\gamma(\sigma_1^2) \mat{Z}\bar{\Omega}_{1,\rho_1} \mat{Z}^\top \right) &
\tr\left(\gamma(\sigma_1^2) \mat{Z}\bar{\Omega}_2\mat{Z}^\top \right) \\
\tr\left(\gamma(\rho_1) \mat{Z}\bar{\Omega}_{1,\sigma_1^2} \mat{Z}^\top \right) & \tr\left(\gamma(\rho_1) \mat{Z}\bar{\Omega}_{1,\rho_1} \mat{Z}^\top \right) &
\tr\left(\gamma(\rho_1) \mat{Z}\bar{\Omega}_2\mat{Z}^\top \right) \\
\tr\left(\gamma(\sigma_2^2) \mat{Z}\bar{\Omega}_{1,\sigma_1^2} \mat{Z}^\top \right) & \tr\left(\gamma(\sigma_2^2) \mat{Z}\bar{\Omega}_{1,\rho_1} \mat{Z}^\top \right) &
\tr\left(\gamma(\sigma_2^2) \mat{Z}\bar{\Omega}_2\mat{Z}^\top \right)
\end{matrix}\right)
\end{align*}

and $\gamma(\theta_l) = K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1}$

### More on the Fixed Point

Inspired by: Chatrchi Golshid (2012): Robust Estimation of Variance Components
in Small Area Estimation, Master-Thesis, Ottawa, Ontario, Canada: p. 16ff.:

\begin{quote}
The fixed-point iterative method relies on the fixed-point theorem: "If g(x) is
a continuous function for all $x \in [a; b]$, then $g$ has a fixed point in $[a;
b]$." This can be proven by assuming that $g(a)\geq a$ and $g(b)\leq b$. Since
$g$ is continuous the intermediate value theorem guarantees that there exists a
$c$ such that $g(c) = c$.
\end{quote}

Starting from equation \ref{eq:rml_theta} where $\theta = \sigre$ we can rewrite
the equation such that:

\begin{align}
\label{eq:rml_theta_fp}
\Phi(\theta) = \aFH - \tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta} (\mat{Z}\mat{G}\mat{Z}^\top)^{-1} (\mat{Z}\mat{G}\mat{Z}^\top)\right) =& 0
\end{align}

Note that because the matrix $\mat{R}$ is assumed to be known for the FH model,
it can be omitted. Note that under the simple Fay-Herriot Model
$\mat{Z}\mat{G}\mat{Z}^\top = \sigre\mat{I}$, where $\mat{I}$ is a $(D \times
D)$ identity matrix. Furthermore $\frac{\partial\mat{V}}{\partial\theta} =
\mat{I}$. Thus equation \ref{eq:rml_theta_fp} can be rewritten to:

\begin{align*}
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) = \tr\left(K\mat{V}^{-1}\mat{G}^{-1} \sigre \right)
\end{align*}

This can be solved for the fixed Point and is directly presented in algorithmic
notation, such that:
$$
\theta^{m+1} = A(\theta^{(m)})^{-1} a(\theta^{(m)}) \text{ ,}
$$
where
$$
A(\theta) = \tr\left(K\mat{V}^{-1}\mat{G}^{-1} \right)
$$
and
$$a(\theta) = \psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r})
$$

