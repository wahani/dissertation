# Extensions to the Fay-Herriot Model

In the following you will find the models for which robust parameter estimates
are provided. This includes the methods reviewed in section(?) but also the FH
model. These models will be framed in the context of linear mixed models and
some details on derivatives are provided. The robust estimation equations are -
where possible - stated for the general case of linear mixed models. Hence the
specifications of these sections can then simply be *plugged into* the robust
estimation equations without the need to explicitly stating them for each
extension.

## Fay-Herriot Model

For a review of the FH model see section (?). In the following the model is
stated for consistent notation and the sace of completeness.
\empty{
\begin{align*}
\tilde{\mat{y}} & = \mat{X} \pmat\beta + \mat{Z}\mat{u} + \mat{e} \\
\mat{u} & \sim \Distr{N}\Paran{\mat{0}_D, \mat{V}_u} \\
\mat{e} & \sim \Distr{N}\Paran{\mat{0}_D, \mat{V}_e}
\end{align*}
}where $\tilde{\mat{y}}$ denotes the $(D \times 1)$ vector of observed direct 
estimates; $\mat{X}$ the $(D \times P)$ design matrix; $\pmat\beta$ the $(P 
\times 1)$ vector of regression coefficients; $\mat{Z} = \mat{I}_{D \times D}$ 
is an identity matrix; $\mat{u}$ is a $(D \times 1)$ vector of random effects; 
and $\mat{e}$ is the $(D \times 1)$ vector of sampling errors. Furthermore
$\mat{0}_r$ denotes a $(r \times 1)$ vector containing zeros; $\mat{V}_u =
\mat{V}_u(\sigma_\re^2) = \sigma_\re^2 \mat{I}_{D \times D}$ is the variance
covariance matrix of $\mat{u}$; and $\mat{V}_e = \diag{\{\sige\}_{i = 1}^D}$
with known sampling variances $\{\sige\}_{i = 1}^D$. Hence the unknown model
parameters are $\pmat\beta$ and $\pmat\delta = (\sigre)$.


## Spatial Fay-Herriot Model

For a review of spatial extensions to the FH model see section (?). Here model
(?) is represented as linear mixed model so that it can be represented as:
\empty{
\begin{align*}
\tilde{\mat{y}} & = \mat{X} \pmat\beta + \mat{Z}\mat{u} + \mat{e} \\
\mat{u} & \sim \Distr{N}\Paran{\mat{0}_D, \mat{V}_u} \\
\mat{e} & \sim \Distr{N}\Paran{\mat{0}_D, \mat{V}_e}
\end{align*}
}where the notation is the same as for the FH model with the following
differences: $\mat{u} = \mat{u}_1$ with $\mat{u}_1$ being the $(D \times 1)$
vector of spatially correlated random effects following a SAR(1):
\empty{
\begin{align*}
u_{1i} & = \rho_1 \sum_{l\neq i}w_{il} u_{1l} + \epsilon_{1i} \\
\epsilon_{1i} & \sim \Distr{N}(0, \sigma_1^2) \text{ i.i.d.}\\
\text{with }i & = 1, \dots, D,
\end{align*}
}where $w_{il}$ are the elements of the row standardized proximity matrix 
$\mat{W}$. Let $\mat{W}^0$ denote the proximity matrix then a possible
definition of $\mat{W}^0$ is that the elements are equal to one if area $i$ and
$l$ are neighboured and zero otherwise. This leads to the following distribution of
$\mat{u}_1$:
\empty{
\begin{align*}
\mat{u}_1 & \sim \Distr{N}\Paran{\mat{0}_D, \sigma_{1}^2 \pmat\Omega(\rho_1)}
\intertext{where}
\pmat\Omega_1(\rho_1) & = \Paran{(\mat{I}_{D\times D} - \rho_1\mat{W})^\top (\mat{I}_{D\times D} - \rho_1\mat{W})}^{-1}
\end{align*}
}and hence $\mat{V}_u = \sigma_{1}^2 \Omega(\rho_1)$. Thus the unknown model
parameters are $\pmat\beta$ and $\pmat\delta = (\rho_1, \sigma_1^2)$.


## Temporal Fay-Herriot Model

A review of temporal extensions can be found in section (?). In the following you will find the representation of the temporal model underlying (?) as a linear mixed model:
\empty{
\begin{align*}
\tilde{\mat{y}} & = \mat{X} \pmat\beta + \mat{Z}\mat{u} + \mat{e} \\
\mat{u} & \sim \Distr{N}\Paran{\mat{0}_{D+DT}, \mat{V}_u} \\
\mat{e} & \sim \Distr{N}\Paran{\mat{0}_{D+DT}, \mat{V}_e}
\end{align*}
}where $\tilde{\mat{y}}$ denotes the $(DT \times 1)$ vector of observed direct 
estimates; $\mat{X}$ the $(DT \times P)$ design matrix; $\pmat\beta$ the $(P 
\times 1)$ vector of regression coefficients; $\mat{Z} = (\mat{Z}_1, \mat{Z}_2)$
where $\mat{Z}_1 = \mat{I}_{D \times D} \otimes (\mat{1}_T)^\top$, $\mat{1}_T$
is a $T \times 1$ vector of ones, and $\mat{Z}_2 = \mat{I}_{DT}$; $\mat{u} =
(\mat{u}_0, \mat{u}_2)$ is the $(D + DT \times 1)$ vector of random effects; and
$\mat{e}$ is the $(DT \times 1)$ vector of sampling errors. Note that
$\mat{u}_0$ denotes the vector of random effects similar to the FH model in that
$\mat{u}_0 \sim \Distr{N}(\mat{0}_D, \sigre\mat{I}_D)$. $\mat{u}_2$ is a $(DT
\times 1)$ vector of autocorrelated random effects following a AR(1):
$$
\re_{2it} = \rho_2 \re_{2i, t-1} + \epsilon_{2it}
$$
with $i = 1, \dots, D$ and $t = 1, \dots, T$, where $\rho_2$ is the auto
correlation coefficient with $|\rho_2| < 1$ and $\epsilon_{2it} \sim
\Distr{N}(0, \sigma_2^2)$. Furthermore $\mat{u}_0$, $\mat{u}_2$ and $\mat{e}$
are independent. Hence the distribution of $\mat{u}_2$ is given by:
\empty{
\begin{align*}
\mat{u}_2 \sim \Distr{N}\Paran{\mat{0}_{DT}, \sigma_2^2\pmat\Omega(\rho_2)} 
\end{align*}
}where $\pmat\Omega(\rho_2)$ is a block diagonal matrix in which each block is defined by:
$$
\pmat\Omega_{2i}(\rho_2) = \frac{1}{1-\rho_2^2}
\left(
  \begin{matrix}
    1 & \rho_2 & \cdots & \rho_2^{T-2}& \rho_2^{T-1}\\
    \rho_2 & 1 & & & \rho_2^{T-2} \\
    \vdots & & \ddots & & \vdots \\
    \rho_2^{T-2} &&& 1 & \rho_2 \\
    \rho_2^{T-1} & \rho_2^{T-2} & \cdots & \rho_2 & 1\\
  \end{matrix}
\right)_{T\times T}
$$
with $i = 1, \dots, D$. Thus $\mat{V}_u = \mat{V}_u(\pmat\delta) = 
\Diag{\sigma_\re^2 \mat{I}_{D}, \sigma_2^2\pmat\Omega(\rho_2)}$ is the variance 
covariance matrix of $\mat{u}$; and $\mat{V}_e = \Diag{\{\{\sigma_{eit}^2\}_{t =
1}^T\}_{i = 1}^D}$ is the variance covariance matrix of $\mat{e}$ with known
sampling variances for each time period and area. Hence the unknown model 
parameters are $\pmat\beta$ and $\pmat\delta = (\sigre, \rho_2, \sigma_2^2)$.


## Spatio-Temporal Fay-Herriot Model

The review of this type of models can be found in section (?). The following
presents the spatio-temporal model introduced by @Mar13 as a linear mixed model
in the form:
\empty{
\begin{align*}
\tilde{\mat{y}} & = \mat{X} \pmat\beta + \mat{Z}\mat{u} + \mat{e} \\
\mat{u} & \sim \Distr{N}\Paran{\mat{0}_{D+DT}, \mat{V}_u} \\
\mat{e} & \sim \Distr{N}\Paran{\mat{0}_{D+DT}, \mat{V}_e}
\end{align*}
}where the notation is the same as for the temporal model with the following 
differences: here $\mat{u} = (\mat{u}_1, \mat{u}_2)$ where $\mat{u}_1$ denotes 
the spatially correlated random effect of section (?) and $\mat{u}_2$ the 
autocorrelated random effect as in section (?). Thus the variance structure of
$\mat{u}$ is given by $\mat{V}_u = \mat{V}_u(\pmat\delta) =
\Diag{\sigma_1^2\pmat\Omega_1(\rho_1), \sigma_2^2\pmat\Omega_2(\rho_2)}$ and
hence the unknown model parameters are $\pmat\beta$ and $\pmat\delta = (\rho_1,
\sigma_1^2, \rho_2, \sigma_2^2)$.


# Robust Predictions under Area Level Models

## Robust Estimation Equations

## Pseudolinear Representation

\empty{
\begin{align*}
\sum_i \mat{X}_i^\top\mat{v}_i^{-1} v_{ii}^{\half} 
  \psi\Paran{v_{ii}^{-\half} (y_i - \mat{x}^\top_i\beta)} & = 0
\end{align*}
}


\empty{
\begin{align*}
\mat{X}^\top\mat{V}^{-1} \mat{U}^{\half} 
  \psi\Paran{\mat{U}^{-\half} (\mat{y} - \mat{X}\beta)} & = 0 \\
\underbrace{\mat{X}^\top\mat{V}^{-1} \mat{U}^{\half} \mat{W}_1
  \mat{U}^{-\half}}_{\mat{W}_1^*} (\mat{y} - \mat{X}\beta) & = 0 \\
\mat{W}_1^* \mat{y} & = \mat{W}_1^* \mat{X}\beta \\
\underbrace{\Paran{\mat{W}_1^* \mat{X}}^{-1} \mat{W}_1^*}_{\mat{A}} 
  \mat{y} & = \beta
\end{align*}
}

with

\empty{
\begin{align*}
\mat{A} = \Paran{\mat{X}^\top\mat{V}^{-1} \mat{U}^{\half} \mat{W}_1
  \mat{U}^{-\half} \mat{X}}^{-1} \mat{X}^\top\mat{V}^{-1} \mat{U}^{\half} \mat{W}_1
  \mat{U}^{-\half}
\end{align*}
}

\empty{
\begin{align*}
\mat{u} & = \mat{B}\Paran{\mat{I} - \mat{X}\mat{A}} \mat{y} \\
        & = \mat{B}\Paran{\mat{y} - \mat{X}\beta}
\end{align*}
}

\empty{
\begin{align*}
\mat{Z}^\top \mat{V}_e^{-\half} \psi \Paran{\mat{V}_e^{-\half} 
  \Paran{\mat{y}-\mat{X}\beta - \mat{Z} \mat{\re}}} 
  - \mat{V}_\re^{-\half} \psi\Paran{\mat{V}_\re^{-\half}\mat{\re}} & = 0 \\
%
\underbrace{\mat{Z}^\top \mat{V}_e^{-\half} \mat{W}_2 \mat{V}_e^{-\half}}_{\mat{W}^*_2}
  \Paran{\mat{y}-\mat{X}\beta - \mat{Z} \mat{\re}} 
  - \underbrace{\mat{V}_\re^{-\half} \mat{W}_3 \mat{V}_\re^{-\half}}_{\mat{W}_3^*} \mat{\re} & = 0
%  
\end{align*}
}

\empty{
\begin{align*}
\mat{W}_2^* \Paran{\mat{y}-\mat{X}\beta - \mat{Z} \mat{\re}} & = 
  \mat{W}_3^*\mat{\re} \\
%
\mat{W}_2^* \Paran{\mat{y}-\mat{X}\beta} & = 
  \Paran{\mat{W}_2^*\mat{Z} + \mat{W}_3^*} \mat{\re} \\
%
\underbrace{\Paran{\mat{W}_2^*\mat{Z} + \mat{W}_3^*}^{-1} \mat{W}_2^*}_{\mat{B}} 
  \Paran{\mat{y}-\mat{X}\beta} & = \mat{\re}
\end{align*}
}

where 
$$
\mat{B}(\mat{u}) = \mat{B} = 
  \Paran{
    \mat{Z}^\top \mat{V}_e^{-\half} \mat{W}_2 \mat{V}_e^{-\half} \mat{Z}
    + \mat{V}_\re^{-\half} \mat{W}_3 \mat{V}_\re^{-\half}
  }^{-1} \mat{Z}^\top \mat{V}_e^{-\half} \mat{W}_2 \mat{V}_e^{-\half}
$$


## Solutions to the Robust Estimation Equations

### Newton Raphson Algorithms

@Sin09 propose a Newton-Raphson algorithm to solve equations \ref{eq:rml_beta} and \ref{eq:rml_theta} iteratively. The iterative equation for $\beta$ is given by:
$$
\beta^{(m+1)} = \beta^{(m)} + \left(\mathbf{X}^\top \mathbf{V}^{-1}\mathbf{D}(\beta^{(m)})\mathbf{X}\right)^{-1}\mathbf{X}^\top\mathbf{V}^{-1}\mathbf{U}^{\frac{1}{2}}\psi(\mathbf{r}(\beta^{(m)}))
$$
where $\mathbf{D}(\beta) = \frac{\partial \psi(\mathbf{r})}{\partial \mathbf{r}}$ is a diagonal matrix of the same order as $\mathbf{V}$ with elements
$$
D_{jj} =
\begin{cases}
1 \text{ for } |r_j|\leq b\\
0 \text{ else}
\end{cases}
\text{ , } j = 1, \dots, n
$$
The iterative equation for $\theta$ can be stated as:
$$
\theta^{(m+1)} = \theta^{(m)} - \left( \Phi'(\theta^{(m)}) \right)^{-1} \Phi(\theta^{(m)})
$$
where $\Phi'(\theta^m)$ is the derivative of $\Phi(\theta)$ evaluated at $\theta^{(m)}$. The derivative of $\Phi$ is given by \cite[p.53]{Sch11}:
\begin{align}
\label{eq:deriv_Phi_theta}
\frac{\partial\Phi}{\partial\theta_l} = 2\frac{\partial}{\partial\theta_l}\left(\psi(\mathbf{r})^\top\mathbf{U}^{\frac{1}{2}}\mathbf{V}^{-1}\right)\frac{\partial\mathbf{V}}{\partial\theta_l}\mathbf{V}^{-1}\mathbf{U}^{\frac{1}{2}}\psi(\mathbf{r}) + \tr\left(\mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\theta_l}\mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\theta_l} K\right)
\end{align}
where
$$
\frac{\partial}{\partial\theta_l}\left(\psi(\mathbf{r})^\top\mathbf{U}^{\frac{1}{2}}\mathbf{V}^{-1}\right) = \frac{\partial}{\partial\theta_l}(\psi(\mathbf{r})^\top)\mathbf{U}^\frac{1}{2}\mathbf{V}^{-1} + \psi(\mathbf{r})^\top\frac{\partial}{\partial\theta_l}(\mathbf{U}^\frac{1}{2})\mathbf{V}^{-1} - \psi(\mathbf{r})^\top\mathbf{U}^\frac{1}{2}\mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\theta_l}\mathbf{V}^{-1}.
$$
In @Sch11 adopted this procedure for the Spatial Robust EBLUP and essentially we will follow the same procedure @Sch11[p.74ff.]. Thus we will directly consider the algorithm for the Spatio Temporal model introduced earlier. Since the model considered by @Sin09 contained a block diagonal variance structure where all off-diagonals are zero, equation \ref{eq:deriv_Phi_theta} is valid with respect to the earlier specified variance parameters $\sigma_1^2$ and $\sigma_2^2$ from the spatio temporal Fay Herriot model. The derivative of $\Phi$ with respect to $\rho_1$ and $\rho_2$, however, is different. To adapt the notation, let $\theta = (\sigma_1^2, \sigma_2^2)$ for which equation \ref{eq:deriv_Phi_theta} holds. Let $\rho = (\rho_1, \rho_2)$ denote the vector of correlation parameters as they already have been defined above. Then the iterative equation for $\rho$ is can be stated as:
$$
\rho^{(m+1)} = \rho^{(m)} + \left(\Phi'(\rho^{(m)}\right)^{-1}\Phi(\rho^{(m)})
$$
where the derivative of $\Phi$ with respect to $\rho$ is given by @Sch11[p.76]:

\begin{align*}
\frac{\partial\Phi}{\partial\rho_l} =& 2\frac{\partial}{\partial\rho_l}\left(\psi(\mathbf{r})^\top\mathbf{U}^{\frac{1}{2}}\mathbf{V}^{-1}\right)\frac{\partial\mathbf{V}}{\partial\rho_l}\mathbf{V}^{-1}\mathbf{U}^{\frac{1}{2}}\psi(\mathbf{r})\\
&+ \psi(\mathbf{r})^\top\mathbf{U}^{\frac{1}{2}}\mathbf{V}^{-1} \frac{\partial\mathbf{V}}{\partial\rho_l\partial\rho_l} \mathbf{V}^{-1}\mathbf{U}^{\frac{1}{2}}\psi(\mathbf{r}) \\
&+ \tr\left(\mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\rho_l\partial\rho_l} K - \mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\theta_l}\mathbf{V}^{-1}\frac{\partial\mathbf{V}}{\partial\theta_l} K\right)
\end{align*}

The partial derivatives of $\mathbf{V}$ with respect to $\theta$ and $\rho$ are given by:

\begin{align*}
\frac{\partial\mathbf{V}}{\partial\sigma_1^2} =& \mathbf{Z}_1\Omega_1(\rho_1)\mathbf{Z}_1^\top \\
\frac{\partial\mathbf{V}}{\partial\sigma_2^2} =& \Omega_2(\rho_2) \\
\frac{\partial\mathbf{V}}{\partial\rho_1} =& -\sigma_1^2\mathbf{Z}_1\Omega_1(\rho_1)\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1}\Omega_1(\rho_1)\mathbf{Z}^\top_1 \\
\frac{\partial\mathbf{V}}{\partial\rho_2} =& \sigma_2^2 \diag\left(\frac{\partial\Omega_{2d}(\rho_2)}{\partial\rho_2}\right) \\
\frac{\partial\mathbf{V}}{\partial\rho_1\partial\rho_1} =& -\sigma_1^2\mathbf{Z}_1\frac{\partial\Omega_1(\rho_1)}{\partial\rho_1}\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1}\Omega_1(\rho_1)\mathbf{Z}^\top_1 \\
&-\sigma_1^2\mathbf{Z}_1\Omega_1(\rho_1)\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1\partial\rho_1}\Omega_1(\rho_1)\mathbf{Z}^\top_1 \\
&-\sigma_1^2\mathbf{Z}_1\Omega_1(\rho_1)\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1}\frac{\partial\Omega_1(\rho_1)}{\partial\rho_1}\mathbf{Z}^\top_1 \\
\frac{\partial\mathbf{V}}{\partial\rho_2\partial\rho_2} =& \text{Needs to be TEXed}
\end{align*}

where

\begin{align*}
\frac{\Omega_1(\rho_1)}{\partial\rho_1} =& -\Omega_1(\rho_1)\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1}\Omega_1(\rho_1) \text{ , }\\
\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1} =& -\mathbf{W} - \mathbf{W}^\top + 2\rho_1\mathbf{W}^\top\mathbf{W} \text{ , } \\
\frac{\partial\Omega_1^{-1}(\rho_1)}{\partial\rho_1\partial\rho_1} =& 2\mathbf{W}^\top\mathbf{W}\\
\frac{\partial\Omega_{2d}(\rho_2)}{\partial\rho_2} =& \frac{1}{1-\rho_2^2}
\left(
\begin{matrix}
0 & 1 & \cdots & \cdots & (T-1)\rho_2^{T-2}\\
1 & 0 & & & (T-2)\rho_2^{T-3} \\
\vdots & & \ddots & & \vdots \\
(T-2)\rho_2^{T-3} &&& 0 & 1 \\
(T-1)\rho_2^{T-2} & \cdots & \cdots & 1 & 0\\
\end{matrix}
\right) + \frac{2\rho_2\Omega_{2d}(\rho_2)}{1-\rho_2^2}
\end{align*}

Having identified all iterative equations the adapted algorithm from @Sch11 is as follows:

- Choose initial values for $\beta^0$, $\theta^0$ and $\rho^0$.
  - Compute $\beta^{(m+1)}$, with given variance parameters and correlation parameters
	- Compute $\theta^{(m+1)}$, with given regression and correlation parameters
	- Compute $\rho^{(m+1)}$, with given variance and regression parameters

- Continue step 2 until the following stopping rule holds:

\begin{align*}
	||\beta^{(m+1)}- \beta^{(m)}||^2 <& \text{const} \\
	(\sigma_1^{2(m+1)} - \sigma_1^{2(m)})^2 + (\sigma_2^{2(m+1)} - \sigma_2^{2(m)})^2 + (\rho_1^{(m+1)} - \rho_1^{(m)})^2 + (\rho_2^{(m+1)} - \rho_2^{(m)})^2 <& \text{const}
\end{align*}


### Fixed Point Algorithms

Inspired by: Chatrchi Golshid (2012): Robust Estimation of Variance Components
in Small Area Estimation, Master-Thesis, Ottawa, Ontario, Canada: p. 16ff.:

\begin{quote}
The fixed-point iterative method relies on the fixed-point theorem: "If g(x) is
a continuous function for all $x \in [a; b]$, then $g$ has a fixed point in $[a;
b]$." This can be proven by assuming that $g(a)\geq a$ and $g(b)\leq b$. Since
$g$ is continuous the intermediate value theorem guarantees that there exists a
$c$ such that $g(c) = c$.
\end{quote}

Starting from equation \ref{eq:rml_theta} where $\theta = (\sigma_1^2,
\sigma_2^2)$ and $(\rho_1, \rho_2)$ are assumed to be known, we can rewrite the
equation such that:

\begin{multline}
\label{eq:rml_theta_fp}
\Phi_l(\theta) = \psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}
\frac{\partial\mat{V}}{\partial\theta_l}
\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) -\\
\Tr{K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l}
(\mat{Z}\mat{V}_\re\mat{Z}^\top)^{-1} (\mat{Z}\mat{V}_\re\mat{Z}^\top)} = 0
\end{multline}

Note that because the matrix $\mat{V}_e$ is assumed to be known for the FH
model, it can be omitted. Let $\mat{0}_{r\times c}$ define a matrix filled with
$0$ of dimension $(r \times c)$ then:

\begin{align*}
\mat{Z}\mat{V}_u\mat{Z}^\top =& \mat{Z}\left(\begin{matrix}
\sigma_1^2\Omega_1 & \mat{0}_{D\times DT}\\
\mat{0}_{DT\times D} &  \sigma_2^2\Omega_2
\end{matrix}\right)\mat{Z}^\top \\
=& \mat{Z}
\left[
\sigma_1^2\left(\begin{matrix}
\Omega_1 & \mat{0}_{D\times DT} \\
\mat{0}_{DT\times D} &  \mat{0}_{DT\times DT}
\end{matrix}\right) +
\sigma_2^2\left(\begin{matrix}
\mat{0}_{D\times D} & \mat{0}_{D\times DT} \\
\mat{0}_{DT\times D} & \Omega_2
\end{matrix}\right)
\right]\mat{Z}^\top \\
=& \left(\begin{matrix}\mat{Z}\bar{\Omega}_1\mat{Z}^\top & \mat{Z}\bar{\Omega}_2\mat{Z}^\top\end{matrix}\right)
\left(\begin{matrix}
\sigma_1^2 \\
\sigma_2^2
\end{matrix}\right)
\end{align*}

Thus equation \ref{eq:rml_theta_fp} can be rewritten to:

\begin{multline*}
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) = \\ \tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \left(\begin{matrix}\mat{Z}\bar{\Omega}_1\mat{Z}^\top & \mat{Z}\bar{\Omega}_2\mat{Z}^\top\end{matrix}\right)\left(\begin{matrix}
\sigma_1^2 \\
\sigma_2^2
\end{matrix}\right)\right)
\end{multline*}

Let
$$
\left(\begin{matrix}
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_1^2}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) \\
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_2^2}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r})
\end{matrix}\right)
= a(\theta) \text{ ,}
$$
then
$$
\theta = \left(\begin{matrix}
\sigma_1^2 \\
\sigma_2^2
\end{matrix}\right) = A(\theta)^{-1} a(\theta) \text{ ,}
$$
where
\begin{align*}
A(\theta) = \left(\begin{matrix}
\tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_1^2} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \mat{Z}\bar{\Omega}_1\mat{Z}^\top \right) &
\tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_1^2} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \mat{Z}\bar{\Omega}_2\mat{Z}^\top \right) \\
\tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_2^2} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \mat{Z}\bar{\Omega}_1\mat{Z}^\top \right) &
\tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_2^2} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \mat{Z}\bar{\Omega}_2\mat{Z}^\top \right)
\end{matrix}\right) \text{.}
\end{align*}
So, the fixed point algorithm can be presented as follows:
$$
\theta^{m+1} = A(\theta^{(m)})^{-1} a(\theta^{(m)})
$$

At this time the fixed-point algorithm for $\theta = (\sigma_1^2, \sigma_2^2)$
will replace the corresponding step in Issue 1.

### N-S: Fixed-Point-Algorithm - Spatial Correlation

To extend the above algorithm to not only being used for the estimation of
$\theta = (\sigma_1^2, \sigma_2^2)$ but also for the spatial correlation
parameter $\rho_1$ reconsider:

\begin{eqnarray}
\label{eq:zVuZ_rho1_1}
\mat{Z}\mat{V}_u\mat{Z}^\top &=& \mat{Z}\left(\begin{matrix}
\sigma_1^2\Omega_1 & \mat{0}_{D\times DT}\\
\mat{0}_{DT\times D} &  \sigma_2^2\Omega_2
\end{matrix}\right)\mat{Z}^\top
\end{eqnarray}

and the specification of $\Omega_1(\rho_1) = \left((I-\rho_1\mat{W})^\top(I-\rho_1\mat{W})\right)^{-1}$:

\begin{align}
\sigma_1^2\Omega_1(\rho_1) &= \sigma_1^2\Omega_1\Omega_1(I-\rho_1\mat{W})^\top(I-\rho_1\mat{W}) \notag\\
&= \sigma_1^2\left(\Omega_1\Omega_1 -\rho_1\Omega_1\Omega_1\mat{W}^\top -\rho_1\Omega_1\Omega_1\mat{W} + \rho_1^2\Omega_1\Omega_1\mat{W}^\top\mat{W}\right) \notag\\
&= \sigma_1^2\left(\Omega_1\Omega_1 -\rho_1\Omega_1\Omega_1\mat{W}^\top\right) +\rho_1 \left(-\sigma_1^2\Omega_1\Omega_1\mat{W} + \sigma_1^2\rho_1\Omega_1\Omega_1\mat{W}^\top\mat{W}\right) \label{eq:zVuZ_rho1_2}
\end{align}

Thus equation \ref{eq:zVuZ_rho1_1} can be rewritten as:

\begin{align*}
\mat{Z}\mat{V}_u\mat{Z}^\top
&=\mat{Z}
\Biggr[
\sigma_1^2\left(\begin{matrix}
\Omega_1\Omega_1 -\rho_1\Omega_1\Omega_1\mat{W}^\top & \mat{0}_{D\times DT}\\
\mat{0}_{DT\times D} &  \mat{0}_{DT\times DT}
\end{matrix}\right)\\
&+\rho_1\left(\begin{matrix}
-\sigma_1^2\Omega_1\Omega_1\mat{W} + \sigma_1^2\rho_1\Omega_1\Omega_1\mat{W}^\top\mat{W} & \mat{0}_{D\times DT}\\
\mat{0}_{DT\times D} &  \mat{0}_{DT\times DT}
\end{matrix}\right)\\
&+\sigma_2^2\left(\begin{matrix}
\mat{0}_{D\times D} & \mat{0}_{D\times DT}\\
\mat{0}_{DT\times D} & \Omega_2
\end{matrix}\right)
\Biggr]
\mat{Z}^\top \\
&=\left(\begin{matrix}\mat{Z}\bar{\Omega}_{1, \sigma_1^2}\mat{Z}^\top &
\mat{Z}\bar{\Omega}_{1, \rho_1}\mat{Z}^\top & \mat{Z}\bar{\Omega}_2\mat{Z}^\top\end{matrix}\right)
\left(\begin{matrix}
\sigma_1^2 \\
\rho_1 \\
\sigma_2^2
\end{matrix}\right)
\end{align*}

Thus equation \ref{eq:rml_theta_fp} can be rewritten (analogously as above) to:

\begin{eqnarray*}
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) = \tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1} \left(\begin{matrix}\mat{Z}\bar{\Omega}_{1, \sigma_1^2}\mat{Z}^\top &
\mat{Z}\bar{\Omega}_{1, \rho_1}\mat{Z}^\top & \mat{Z}\bar{\Omega}_2\mat{Z}^\top\end{matrix}\right)
\left(\begin{matrix}
\sigma_1^2 \\
\rho_1 \\
\sigma_2^2
\end{matrix}\right)\right)
\end{eqnarray*}

Let

$$
\left(\begin{matrix}
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_1^2}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) \\
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\rho_1}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) \\
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\sigma_2^2}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r})
\end{matrix}\right)
= a(\theta) \text{ ,}
$$

then

$$
\theta = \left(\begin{matrix}
\sigma_1^2 \\
\rho_1 \\
\sigma_2^2
\end{matrix}\right) = A(\theta)^{-1} a(\theta) \text{ ,}
$$
where
\begin{align*}
A(\theta) = \left(\begin{matrix}
\tr\left(\gamma(\sigma_1^2) \mat{Z}\bar{\Omega}_{1,\sigma_1^2} \mat{Z}^\top \right) & \tr\left(\gamma(\sigma_1^2) \mat{Z}\bar{\Omega}_{1,\rho_1} \mat{Z}^\top \right) &
\tr\left(\gamma(\sigma_1^2) \mat{Z}\bar{\Omega}_2\mat{Z}^\top \right) \\
\tr\left(\gamma(\rho_1) \mat{Z}\bar{\Omega}_{1,\sigma_1^2} \mat{Z}^\top \right) & \tr\left(\gamma(\rho_1) \mat{Z}\bar{\Omega}_{1,\rho_1} \mat{Z}^\top \right) &
\tr\left(\gamma(\rho_1) \mat{Z}\bar{\Omega}_2\mat{Z}^\top \right) \\
\tr\left(\gamma(\sigma_2^2) \mat{Z}\bar{\Omega}_{1,\sigma_1^2} \mat{Z}^\top \right) & \tr\left(\gamma(\sigma_2^2) \mat{Z}\bar{\Omega}_{1,\rho_1} \mat{Z}^\top \right) &
\tr\left(\gamma(\sigma_2^2) \mat{Z}\bar{\Omega}_2\mat{Z}^\top \right)
\end{matrix}\right)
\end{align*}

and $\gamma(\theta_l) = K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta_l} (\mat{Z}\mat{V}_u\mat{Z}^\top)^{-1}$

### More on the Fixed Point

Inspired by: Chatrchi Golshid (2012): Robust Estimation of Variance Components
in Small Area Estimation, Master-Thesis, Ottawa, Ontario, Canada: p. 16ff.:

\begin{quote}
The fixed-point iterative method relies on the fixed-point theorem: "If g(x) is
a continuous function for all $x \in [a; b]$, then $g$ has a fixed point in $[a;
b]$." This can be proven by assuming that $g(a)\geq a$ and $g(b)\leq b$. Since
$g$ is continuous the intermediate value theorem guarantees that there exists a
$c$ such that $g(c) = c$.
\end{quote}

Starting from equation \ref{eq:rml_theta} where $\theta = \sigre$ we can rewrite
the equation such that:

\begin{align}
\label{eq:rml_theta_fp}
\Phi(\theta) = \aFH - \tr\left(K\mat{V}^{-1}\frac{\partial\mat{V}}{\partial\theta} (\mat{Z}\mat{G}\mat{Z}^\top)^{-1} (\mat{Z}\mat{G}\mat{Z}^\top)\right) =& 0
\end{align}

Note that because the matrix $\mat{R}$ is assumed to be known for the FH model,
it can be omitted. Note that under the simple Fay-Herriot Model
$\mat{Z}\mat{G}\mat{Z}^\top = \sigre\mat{I}$, where $\mat{I}$ is a $(D \times
D)$ identity matrix. Furthermore $\frac{\partial\mat{V}}{\partial\theta} =
\mat{I}$. Thus equation \ref{eq:rml_theta_fp} can be rewritten to:

\begin{align*}
\psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r}) = \tr\left(K\mat{V}^{-1}\mat{G}^{-1} \sigre \right)
\end{align*}

This can be solved for the fixed Point and is directly presented in algorithmic
notation, such that:
$$
\theta^{m+1} = A(\theta^{(m)})^{-1} a(\theta^{(m)}) \text{ ,}
$$
where
$$
A(\theta) = \tr\left(K\mat{V}^{-1}\mat{G}^{-1} \right)
$$
and
$$a(\theta) = \psi(\mat{r})^\top\mat{U}^{\frac{1}{2}}\mat{V}^{-1}\mat{V}^{-1}\mat{U}^{\frac{1}{2}} \psi(\mat{r})
$$

