\chapter{Simulation Tools for Small Area Estimation}

# Outline

In this Chapter I want to present a framework for simulation studies within the 
SAE field. The framework is in principle valuable in itself however here it is 
tightly coupled to its implementation: the R-package `saeSim` \citep{War15}. At 
this point it is important to note that the following content has in part been 
published as an article: \citetitle{War16a} -- @War16a. Here a shorter version 
of this article is presented. Content which is related to a general introduction
to the SAE field is omitted; in contrast to the article code examples use the
SAE methods implemented in `saeRobust` \citep{War16} instead of `sae`
\citep{Mol15} to present the tools in a more concise setting. Furthermore text
passages have been changed to integrate the content into the general line of
argumentation of this Thesis.

The set of tools contributed by the package `saeSim` are motivated by providing 
an infrastructure which makes it easier to reproduce results of model and design
based simulation studies. Reproducible research aims at the availability of the 
full academic research, which is the article combined with the full 
computational environment, including data and source code. Open source tools 
like the R\hyp{}language \citep{R} and \LaTeX \space can be used in tight 
integration to combine the statistical analysis with the written words in an 
article. This can be achieved by using tools like `knitr` \citep{Xie13}, 
`sweave` \citep{Lei02}, and more recently `rmarkdown` \citep{All14}. Such tools 
can assist in making research more reproducible. The tools provided by `saeSim`
aim at simplyfying the process of writing the source code for a simulation 
study; in the context of reproducible research this may prove to be useful in
the development of script files as well as in the setting of the tools discussed
earlier.

Real data is often very sensitive and governed by strict confidentiality rules. 
Synthetic data generation mechanisms can be used to provide safe data which can 
be made publicly available -- for a more thorough discussion see @Alf11 and
@Kol11. @Bur14 interpret this as an open research philosophy. Such synthetic
data sets can be used to test newly proposed statistical methods in a
close-to-reality framework. In general, simulation studies in statistics can be
divided into two concepts:

- Design-based: The simulation study is based on true or synthetic data of a 
fixed population. Then, samples are selected repeatedly from the underlying 
finite population and different estimation methods are applied in each 
replication. The estimates so obtained are compared to the true values of the 
population, for instance, in terms of relative bias (RBIAS) and relative root
mean squared prediction error (RRMSPE).
- Model-based: The simulation study uses data directly drawn from a model.
In each iteration the population is generated from a model and a sample is
selected according to a specific sampling scheme. The sample is used to estimate
the target statistic for which quality measures (like the RBIAS and RRMSPE)
are derived.

Further discussion regarding model- and design-based simulations can be found in
@Mue03, @Sal10, and @Alf10.

A closely related software packages in the R-language is `simFrame`
\citep{Alf10} which helps to configure simulation studies in a reproducible
environment. It includes a wide range of features -- like data generation,
sampling schemes, outlier contamination mechanisms, and missing values -- and
has been originally developed for simulations in the context of survey
statistics but is now designed to be as general as possible \citep{Alf10}. The
package `simPop` \citep{Alf14} supports the generation of synthetic population
data. This can be a suitable environment in scenarios where the reproducibility
of results and confidentiality issues play an important role.

In contrast to `simFrame` the package `saeSim` is different in 
design and has a focus on assisting applications in the SAE field. Most 
importantly it is based on a framework which is mapped into the software
package. This framework defines the overall structure and aims to unify the
shared elements between simulation studies. A simulation is here defined
as a stream of data to be manipulated in a sequence of steps. Furthermore it
provides the definition of the interface between these steps. The package 
`saeSim` maps this framework into the R-language and combines it with commonly 
used facilities in this context; e.g. tools for data generation, sampling, and a
link to the parallel computing capabilities in R.

The framework is more concretely presented in the following Section 
\ref{sec:saeSim_framework}. This presentation is followed by code examples in 
Section \ref{sec:saeSim_examples} implementing a simple model-based simulation
study to illustrate the capabilities of the package. Section
\ref{sec:saeSim_discussion} concludes this Chapter with a brief discussion.


# A Simulation Framework
\label{sec:saeSim_framework}

The framework strongly relies on the idea to describe a simulation as a process 
of data manipulation. Independent of simulation studies, @Wic15 and @Wic16
promote this idea by providing tools for cleaning and transforming data. In
those frameworks every defined function takes a `data.frame` as input and 
returns it modified. This leads to a natural connection between all defined 
functions since the result of one function can be directly passed to the next as
an argument. The symbioses of these packages with the pipe operator, `%>%`, from
the package `magrittr` \citep{Bac14} only emphasizes this process.

In `saeSim` this approach is extended to simulation studies in the SAE field.
The main focus is the description of a simulation as a process of data
manipulation. Each step in this process can be defined as a self contained
component -- a function in R -- and thus can be easily replaced, extended, and
reused.

Simulation studies address three different levels; these are the population, the
sample, and data on aggregated level. Figure \ref{fig:flowdiagram} illustrates 
these levels. The left column describes the steps of data manipulation, the 
right column presents the function names in `saeSim` to define the corresponding
steps. The *population\hyp{}level* defines the data on which a study is 
conducted and may be based on real population data, a synthetic population, or 
randomly generated variates from a model. In the context of a design\hyp{}based 
simulation a simulation study is based on true or synthetic data of *one* 
population. In model\hyp{}based simulations the population can be randomly drawn
from a population model in each repetition.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figs/flowdiagram.pdf}
\caption[Process of Simulation]{\label{fig:flowdiagram}Process of Simulation -- Left column are the steps in a simulation. Right column are the corresponding function names to represent those steps in R.} 
\end{figure}

The scope of the framework is not to opt for viewpoints. The aim is to 
incorporate the different simulation concepts in a common framework. The *base* 
-- first component in Figure \ref{fig:flowdiagram} -- of a simulation study is a
data table; here the question is whether this data is *fixed* or *random* over 
simulations. Or from a more technical point of view, is the data generation -- 
the second step in Figure \ref{fig:flowdiagram} -- repeated in each repetition 
or omitted in the study. Depending on the choice of a fixed or random population
it is necessary to re\hyp{}compute the population target statistics like domain
means and variances, or other statistics of interest -- third component in
Figure \ref{fig:flowdiagram}.

The *sample\hyp{}level* is necessary when domain predictions are conducted for 
unit-level models. Independently of how the population is treated - whether as 
fixed or random - this phase consists of two steps: Firstly, drawing a sample 
according to a specific sampling scheme. Secondly, conducting computations on 
the samples -- fourth and fifth component in Figure \ref{fig:flowdiagram}. Given
a sample, small area methods are applied. Of interest are, for instance, 
estimated model parameters, domain predictions, or measures of uncertainty for
the estimates.

Since the sample\hyp{}level is necessary when unit level models are applied, the
*aggregate\hyp{}level* is conducted when area level models are applied -- the 
seventh and last component in Figure \ref{fig:flowdiagram}. Area level models in
SAE typically only use information available for domains -- in
contrast to units. Thus the question for simulation studies for area level 
methods is whether the data is generated on unit level and is used after the 
aggregation -- sixth component in Figure \ref{fig:flowdiagram} -- or whether the
data is generated directly on area level, i.e. drawn from an area level model. 
Depending on whether or not unit-level data and sampling are part of the 
simulation process, the aggregate-level follows the generation of the population
or is based on the aggregated sample.

Depending on the topic of research, some steps in this simulation framework can 
be more relevant than others. The framework defines a complete list of steps
which may be of interest. Single components may be omitted if not relevant in
specific applications. For example *data generation* is not relevant if we have
population data, or the *sample\hyp{}level* is not used when the sample is
directly drawn from the model.

Seen this way, `saeSim` maps the different steps into `R`. Two layers with 
separate responsibilities need to be discussed. The first is *how* different 
simulation components can be combined, and the second is *when* they are 
applied. Regarding the first, in `saeSim` an emphasis is put on the interface of
each component. To be precise, functions are used which take a `data.frame` as 
argument and have a `data.frame` as return value. The return value of one 
component is the input of the next. This definition of interfaces is used for 
all existing tools in `saeSim`. The second column in Figure 
\ref{fig:flowdiagram} shows how the different steps in a simulation can be 
accessed. It is important to note that the functions in Figure 
\ref{fig:flowdiagram} control the process, the second layer, i.e. *when* 
components are applied. Each of these functions take a simulation setup object 
to be modified and a function with the discussed interface as arguments. To 
illustrate these implementation details the following Section gives some code 
examples to implement a model based simulation.

# Code Examples
\label{sec:saeSim_examples}


# Discussion
\label{sec:saeSim_discussion}
