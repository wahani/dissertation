# Overview

In the following I want to give a general overview of the field of small area 
estimation to the extent that it is possible to frame this thesis within the 
field. @Rao03 as well as @Rao15 give a comprehensive overview of established 
methods and research fields. @Gho94, @Rao99, @Pfe02 and @Pfe13 focus on the
status quo and main lines of discussion within the field at their given point in
time.

The problem small area estimation tries to solve, is to produce *reliable 
predictions* of a *target statistic* for *small domains*. A *target statistic* 
can be simple statistics such as means, counts or quantiles but can take any 
form, e.g. an inequality measure like the Gini coefficient for poverty mapping.
Such statistics are produced for *small domains*, where domain refers to
specific groups, e.g. sector of industry or groups defined by socio-economic
characteristics. Because of the frequent application to administrative data
domains are often defined by areas as a geographical unit. They are small in the
sense of few or no sampled units within these domains. This means that a direct
estimation, i.e. an estimation which only relies on the information available
within domains, is not reliable. *Reliability* is here measured by the variance
or mean squared error of the predictions.

Small area estimation tries to improve, often in terms of mean squared error, 
such domain predictions by borrowing strength from other domains. This can
happen by taking additional information from other data sources, like census and
register information, into account. Also structures in the data like spatial or 
temporal correlation can be exploited to improve a prediction.

The importance of the field can be explained by the increasing demand for
reliable estimates by policy makers and official statistics. Results are used
for fund allocation, health programs, agriculture or poverty mapping to name
only a few fields of application. Traditionally such estimates rely on survey
data but as the target domains become more diverse, reliable estimates are
connected to an increasing demand of sampled units within domains. The conflict 
between the demand of predictions for more diverse domains and the costs and 
feasibility for larger samples stimulates the progress within the field; as it 
is the promise to optimize the ratio between sampled units and the reliability
of estimates.

Commonly small area methods are divided into two streams, design\hyp{ }and 
model\hyp{}based methods. Design-based methods can be considered the traditional
methodology for analysing survey data and a comprehensive overview of these 
methods for SAE can be found in @Leh09. Design-based methods summarise different
direct and indirect techniques. The Horvitz-Thompson (HT) estimator (@Hor52) 
which only uses sampled units within domains, and synthetic regression estimates
as well as model\hyp{}assisted methods like generalized regression (GREG)
estimators (@Saer92) are examples for such estimators. What these methods have
in common is that they incorporate information of the sampling design into the
estimation.

Conceptually design- and model-based methods differ in that design\hyp{}based
methods are used to optimally estimate a target parameter of a fixed and finite 
population. Model\hyp{}based methods instead rely on the idea that an observed
sample is drawn from a population which is but one possible realization of a 
*superpopulation* model, and it is the parameters of that superpopulation which 
are targeted. This difference leads to a trade-off when choosing between 
methods: Model-based methods can improve domain estimation in terms of variance 
even with small samples, however, they can not be considered design-unbiased. 
Design-based methods on the other hand are design-unbiased but have larger and 
possibly unacceptable high variances for small samples (see @Leh09).

Model-based methods can be seperated into area\hyp{ }and unit\hyp{}level models.
Observations which can be associated to a specific domain are referred to as 
units. This can be companies within an industry sector or individuals within a 
municipality. The Area-level describes models which use information such as 
direct estimates for domains and rely on area-level information. A situation in
which these models are considered is when data can only be provided as
aggregates due to confidentiality.

One class of models in particular is favoured in different variations: Mixed 
Models. I use the general term of mixed models because it summarizes the
commonality across the many variations in the field. Underlying is the idea to
use auxiliary information in a regression to estimate a global conditional mean
and add an extra component to capture the domain specific difference from that
global mean. This general idea can be found in combination with different
estimation methodologies, i.e. General Linear Mixed Models which is typically
associated with restricted Maximum Likelihood, Empirical Bayes and Hierarchical
Bayes. Although these different frameworks for estimation differ with respect to
optimality criteria, e.g. MSE and squared error loss, equivalence of the 
different derived estimators can be shown for special cases. A more general 
discussion of misxed models in SAE can be found in @Jia06; @Rao03 and @Rao15
provide a comprohensive overview and comparisson of the different frameworks.

A general property of model-based methods is that a lot their benefits in terms
of efficiency rely on strong distributional assumptions. Hence, not only in the 
field of SAE have robust methods been exploited to reduce the negative effect of
a potential violation of these assumptions. The general problem here is that
single observations can have unwanted and overly large impact on results and
such observations are typically called outliers. Such values need to be
distinguished from measurement errors; ...

To summarize robust methods in SAE I want distinguish between three different 
lines of discussion. First, if the distributional assumption - often a gaussian
distribution - appears to be implausible then it is only intuitive to replace
it. This often leads to the use of non-symmetric or heavy-tailed distributions
for the model error or random effect. Due to their flexibility Baysian modelling
strategies are used but also frequntist approaches can be found. Secondly,
methods are applied which are *naturally* more robust against outlying
observations. This includes methods where instead of a conditional global mean a
median - or more generally a quantile - is modelled; but can also mean to use
semi-parametric methods to reduce dependency of the assumptions. The third
approach is to remain with the original model, which often depends on the normal
distribution, and robustify the estimation equations. In this context @Sin09
develop a robustified EBLUP and Buaumont (? Handbook of Statistics 29a) refers
to a winzorization of the Horvitz-Thompson estimator.

Given this background; in this thesis I introduce extensions to the Fay-Herriot
area-level model using a model-based perspective. More precisely an EBLUP based
approach is taken to derive predictions with the possibility to model spatial
and temporal covariance structures. The introduced models are closely related to
the results presented by @Mar13, who introduce spatial and temporal extensions
to the Fay-Herriot model. However, the methods in this thesis are based on an 
estimation procedure which is robust against outliers following the methodology 
introduced by @Sin09. Introduced extensions in the literature around robust 
EBLUPs (REBLUPs) have been focused on unit-level models, thus especially results
to MSE estimation and Bias Correction are extended for area-level models.

Besides contributing to the robust methodology of the field, several
contributions in terms of software are published alongside this dissertation.
@War15 introduces tools for simulation studies for the special case of small
area estimation and (?) implements the methods introduced in this thesis. All
results in this thesis rely on these two packages and a more detailed discussion
can be found in chapter (?).

Extensions take into account different distributional assumptions about the
response variable
@Rao03 as well as @Rao15 give a comprehensive overview on model-based methods in
  SAE. @Cle14 and @Gua15 are examples for reviews appearing for

